{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Muhammad Imran"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  # for getting csv files\n",
    "import numpy as np   #matrix related, first use in np.NaN\n",
    "from sklearn import model_selection  # first use in train,test splitting\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(451, 280)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>75</th>\n",
       "      <th>0</th>\n",
       "      <th>190</th>\n",
       "      <th>80</th>\n",
       "      <th>91</th>\n",
       "      <th>193</th>\n",
       "      <th>371</th>\n",
       "      <th>174</th>\n",
       "      <th>121</th>\n",
       "      <th>-16</th>\n",
       "      <th>...</th>\n",
       "      <th>0.0.38</th>\n",
       "      <th>9.0</th>\n",
       "      <th>-0.9</th>\n",
       "      <th>0.0.39</th>\n",
       "      <th>0.0.40</th>\n",
       "      <th>0.9.3</th>\n",
       "      <th>2.9.1</th>\n",
       "      <th>23.3</th>\n",
       "      <th>49.4</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "      <td>64</td>\n",
       "      <td>81</td>\n",
       "      <td>174</td>\n",
       "      <td>401</td>\n",
       "      <td>149</td>\n",
       "      <td>39</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.1</td>\n",
       "      <td>20.4</td>\n",
       "      <td>38.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>95</td>\n",
       "      <td>138</td>\n",
       "      <td>163</td>\n",
       "      <td>386</td>\n",
       "      <td>185</td>\n",
       "      <td>102</td>\n",
       "      <td>96</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>-2.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3.4</td>\n",
       "      <td>12.3</td>\n",
       "      <td>49.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>175</td>\n",
       "      <td>94</td>\n",
       "      <td>100</td>\n",
       "      <td>202</td>\n",
       "      <td>380</td>\n",
       "      <td>179</td>\n",
       "      <td>143</td>\n",
       "      <td>28</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.2</td>\n",
       "      <td>-2.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2.6</td>\n",
       "      <td>34.6</td>\n",
       "      <td>61.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>190</td>\n",
       "      <td>80</td>\n",
       "      <td>88</td>\n",
       "      <td>181</td>\n",
       "      <td>360</td>\n",
       "      <td>177</td>\n",
       "      <td>103</td>\n",
       "      <td>-16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.1</td>\n",
       "      <td>-3.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>3.9</td>\n",
       "      <td>25.4</td>\n",
       "      <td>62.8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>169</td>\n",
       "      <td>51</td>\n",
       "      <td>100</td>\n",
       "      <td>167</td>\n",
       "      <td>321</td>\n",
       "      <td>174</td>\n",
       "      <td>91</td>\n",
       "      <td>107</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>12.2</td>\n",
       "      <td>-2.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2.2</td>\n",
       "      <td>13.5</td>\n",
       "      <td>31.1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>446</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>160</td>\n",
       "      <td>70</td>\n",
       "      <td>80</td>\n",
       "      <td>199</td>\n",
       "      <td>382</td>\n",
       "      <td>154</td>\n",
       "      <td>117</td>\n",
       "      <td>-37</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.3</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>-4.4</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>447</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>190</td>\n",
       "      <td>85</td>\n",
       "      <td>100</td>\n",
       "      <td>137</td>\n",
       "      <td>361</td>\n",
       "      <td>201</td>\n",
       "      <td>73</td>\n",
       "      <td>86</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.6</td>\n",
       "      <td>-1.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2.4</td>\n",
       "      <td>38.0</td>\n",
       "      <td>62.4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>448</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>166</td>\n",
       "      <td>68</td>\n",
       "      <td>108</td>\n",
       "      <td>176</td>\n",
       "      <td>365</td>\n",
       "      <td>194</td>\n",
       "      <td>116</td>\n",
       "      <td>-85</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.3</td>\n",
       "      <td>-28.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-44.2</td>\n",
       "      <td>-33.2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>449</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>155</td>\n",
       "      <td>55</td>\n",
       "      <td>93</td>\n",
       "      <td>106</td>\n",
       "      <td>386</td>\n",
       "      <td>218</td>\n",
       "      <td>63</td>\n",
       "      <td>54</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.4</td>\n",
       "      <td>25.0</td>\n",
       "      <td>46.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>78</td>\n",
       "      <td>1</td>\n",
       "      <td>160</td>\n",
       "      <td>70</td>\n",
       "      <td>79</td>\n",
       "      <td>127</td>\n",
       "      <td>364</td>\n",
       "      <td>138</td>\n",
       "      <td>78</td>\n",
       "      <td>28</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.4</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.6</td>\n",
       "      <td>21.3</td>\n",
       "      <td>32.8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>451 rows × 280 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     75  0  190  80   91  193  371  174  121  -16  ... 0.0.38   9.0  -0.9  \\\n",
       "0    56  1  165  64   81  174  401  149   39   25  ...    0.0   8.5   0.0   \n",
       "1    54  0  172  95  138  163  386  185  102   96  ...    0.0   9.5  -2.4   \n",
       "2    55  0  175  94  100  202  380  179  143   28  ...    0.0  12.2  -2.2   \n",
       "3    75  0  190  80   88  181  360  177  103  -16  ...    0.0  13.1  -3.6   \n",
       "4    13  0  169  51  100  167  321  174   91  107  ...   -0.6  12.2  -2.8   \n",
       "..   .. ..  ...  ..  ...  ...  ...  ...  ...  ...  ...    ...   ...   ...   \n",
       "446  53  1  160  70   80  199  382  154  117  -37  ...    0.0   4.3  -5.0   \n",
       "447  37  0  190  85  100  137  361  201   73   86  ...    0.0  15.6  -1.6   \n",
       "448  36  0  166  68  108  176  365  194  116  -85  ...    0.0  16.3 -28.6   \n",
       "449  32  1  155  55   93  106  386  218   63   54  ...   -0.4  12.0  -0.7   \n",
       "450  78  1  160  70   79  127  364  138   78   28  ...    0.0  10.4  -1.8   \n",
       "\n",
       "    0.0.39 0.0.40  0.9.3  2.9.1  23.3  49.4   8  \n",
       "0      0.0    0.0    0.2    2.1  20.4  38.8   6  \n",
       "1      0.0    0.0    0.3    3.4  12.3  49.0  10  \n",
       "2      0.0    0.0    0.4    2.6  34.6  61.6   1  \n",
       "3      0.0    0.0   -0.1    3.9  25.4  62.8   7  \n",
       "4      0.0    0.0    0.9    2.2  13.5  31.1  14  \n",
       "..     ...    ...    ...    ...   ...   ...  ..  \n",
       "446    0.0    0.0    0.7    0.6  -4.4  -0.5   1  \n",
       "447    0.0    0.0    0.4    2.4  38.0  62.4  10  \n",
       "448    0.0    0.0    1.5    1.0 -44.2 -33.2   2  \n",
       "449    0.0    0.0    0.5    2.4  25.0  46.6   1  \n",
       "450    0.0    0.0    0.5    1.6  21.3  32.8   1  \n",
       "\n",
       "[451 rows x 280 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_file = open(\"arrhythmia.data\")   #assigning numeric values to data_file\n",
    "\n",
    "arrhythmia=pd.read_csv(data_file)     #read those numeric values as data frame and assign them to arrhythmia\n",
    "df = arrhythmia                       #change it's name alias of data frame, it makes difficulty to use again and again\n",
    "print(df.shape)                       # 451 rows, 280 columns\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>270</th>\n",
       "      <th>271</th>\n",
       "      <th>272</th>\n",
       "      <th>273</th>\n",
       "      <th>274</th>\n",
       "      <th>275</th>\n",
       "      <th>276</th>\n",
       "      <th>277</th>\n",
       "      <th>278</th>\n",
       "      <th>279</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "      <td>64</td>\n",
       "      <td>81</td>\n",
       "      <td>174</td>\n",
       "      <td>401</td>\n",
       "      <td>149</td>\n",
       "      <td>39</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.1</td>\n",
       "      <td>20.4</td>\n",
       "      <td>38.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>95</td>\n",
       "      <td>138</td>\n",
       "      <td>163</td>\n",
       "      <td>386</td>\n",
       "      <td>185</td>\n",
       "      <td>102</td>\n",
       "      <td>96</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>-2.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3.4</td>\n",
       "      <td>12.3</td>\n",
       "      <td>49.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>175</td>\n",
       "      <td>94</td>\n",
       "      <td>100</td>\n",
       "      <td>202</td>\n",
       "      <td>380</td>\n",
       "      <td>179</td>\n",
       "      <td>143</td>\n",
       "      <td>28</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.2</td>\n",
       "      <td>-2.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2.6</td>\n",
       "      <td>34.6</td>\n",
       "      <td>61.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>190</td>\n",
       "      <td>80</td>\n",
       "      <td>88</td>\n",
       "      <td>181</td>\n",
       "      <td>360</td>\n",
       "      <td>177</td>\n",
       "      <td>103</td>\n",
       "      <td>-16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.1</td>\n",
       "      <td>-3.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>3.9</td>\n",
       "      <td>25.4</td>\n",
       "      <td>62.8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>169</td>\n",
       "      <td>51</td>\n",
       "      <td>100</td>\n",
       "      <td>167</td>\n",
       "      <td>321</td>\n",
       "      <td>174</td>\n",
       "      <td>91</td>\n",
       "      <td>107</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>12.2</td>\n",
       "      <td>-2.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2.2</td>\n",
       "      <td>13.5</td>\n",
       "      <td>31.1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>446</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>160</td>\n",
       "      <td>70</td>\n",
       "      <td>80</td>\n",
       "      <td>199</td>\n",
       "      <td>382</td>\n",
       "      <td>154</td>\n",
       "      <td>117</td>\n",
       "      <td>-37</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.3</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>-4.4</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>447</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>190</td>\n",
       "      <td>85</td>\n",
       "      <td>100</td>\n",
       "      <td>137</td>\n",
       "      <td>361</td>\n",
       "      <td>201</td>\n",
       "      <td>73</td>\n",
       "      <td>86</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.6</td>\n",
       "      <td>-1.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2.4</td>\n",
       "      <td>38.0</td>\n",
       "      <td>62.4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>448</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>166</td>\n",
       "      <td>68</td>\n",
       "      <td>108</td>\n",
       "      <td>176</td>\n",
       "      <td>365</td>\n",
       "      <td>194</td>\n",
       "      <td>116</td>\n",
       "      <td>-85</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.3</td>\n",
       "      <td>-28.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-44.2</td>\n",
       "      <td>-33.2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>449</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>155</td>\n",
       "      <td>55</td>\n",
       "      <td>93</td>\n",
       "      <td>106</td>\n",
       "      <td>386</td>\n",
       "      <td>218</td>\n",
       "      <td>63</td>\n",
       "      <td>54</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.4</td>\n",
       "      <td>25.0</td>\n",
       "      <td>46.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>78</td>\n",
       "      <td>1</td>\n",
       "      <td>160</td>\n",
       "      <td>70</td>\n",
       "      <td>79</td>\n",
       "      <td>127</td>\n",
       "      <td>364</td>\n",
       "      <td>138</td>\n",
       "      <td>78</td>\n",
       "      <td>28</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.4</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.6</td>\n",
       "      <td>21.3</td>\n",
       "      <td>32.8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>451 rows × 280 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4    5    6    7    8    9    ...  270   271   272  \\\n",
       "0     56    1  165   64   81  174  401  149   39   25  ...  0.0   8.5   0.0   \n",
       "1     54    0  172   95  138  163  386  185  102   96  ...  0.0   9.5  -2.4   \n",
       "2     55    0  175   94  100  202  380  179  143   28  ...  0.0  12.2  -2.2   \n",
       "3     75    0  190   80   88  181  360  177  103  -16  ...  0.0  13.1  -3.6   \n",
       "4     13    0  169   51  100  167  321  174   91  107  ... -0.6  12.2  -2.8   \n",
       "..   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   ...   ...   \n",
       "446   53    1  160   70   80  199  382  154  117  -37  ...  0.0   4.3  -5.0   \n",
       "447   37    0  190   85  100  137  361  201   73   86  ...  0.0  15.6  -1.6   \n",
       "448   36    0  166   68  108  176  365  194  116  -85  ...  0.0  16.3 -28.6   \n",
       "449   32    1  155   55   93  106  386  218   63   54  ... -0.4  12.0  -0.7   \n",
       "450   78    1  160   70   79  127  364  138   78   28  ...  0.0  10.4  -1.8   \n",
       "\n",
       "     273  274  275  276   277   278  279  \n",
       "0    0.0  0.0  0.2  2.1  20.4  38.8    6  \n",
       "1    0.0  0.0  0.3  3.4  12.3  49.0   10  \n",
       "2    0.0  0.0  0.4  2.6  34.6  61.6    1  \n",
       "3    0.0  0.0 -0.1  3.9  25.4  62.8    7  \n",
       "4    0.0  0.0  0.9  2.2  13.5  31.1   14  \n",
       "..   ...  ...  ...  ...   ...   ...  ...  \n",
       "446  0.0  0.0  0.7  0.6  -4.4  -0.5    1  \n",
       "447  0.0  0.0  0.4  2.4  38.0  62.4   10  \n",
       "448  0.0  0.0  1.5  1.0 -44.2 -33.2    2  \n",
       "449  0.0  0.0  0.5  2.4  25.0  46.6    1  \n",
       "450  0.0  0.0  0.5  1.6  21.3  32.8    1  \n",
       "\n",
       "[451 rows x 280 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns=[i for i in range(280)]   # Convert Column names from 0 to 279\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(451, 280)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>270</th>\n",
       "      <th>271</th>\n",
       "      <th>272</th>\n",
       "      <th>273</th>\n",
       "      <th>274</th>\n",
       "      <th>275</th>\n",
       "      <th>276</th>\n",
       "      <th>277</th>\n",
       "      <th>278</th>\n",
       "      <th>279</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>451.000000</td>\n",
       "      <td>451.000000</td>\n",
       "      <td>451.000000</td>\n",
       "      <td>451.000000</td>\n",
       "      <td>451.000000</td>\n",
       "      <td>451.000000</td>\n",
       "      <td>451.000000</td>\n",
       "      <td>451.000000</td>\n",
       "      <td>451.000000</td>\n",
       "      <td>451.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>451.000000</td>\n",
       "      <td>451.000000</td>\n",
       "      <td>451.000000</td>\n",
       "      <td>451.000000</td>\n",
       "      <td>451.0</td>\n",
       "      <td>451.000000</td>\n",
       "      <td>451.000000</td>\n",
       "      <td>451.000000</td>\n",
       "      <td>451.000000</td>\n",
       "      <td>451.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>46.407982</td>\n",
       "      <td>0.552106</td>\n",
       "      <td>166.135255</td>\n",
       "      <td>68.144124</td>\n",
       "      <td>88.915743</td>\n",
       "      <td>155.068736</td>\n",
       "      <td>367.199557</td>\n",
       "      <td>169.940133</td>\n",
       "      <td>89.935698</td>\n",
       "      <td>33.787140</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.279601</td>\n",
       "      <td>9.048115</td>\n",
       "      <td>-1.458537</td>\n",
       "      <td>0.003991</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.513969</td>\n",
       "      <td>1.218625</td>\n",
       "      <td>19.317295</td>\n",
       "      <td>29.429047</td>\n",
       "      <td>3.871397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>16.429846</td>\n",
       "      <td>0.497830</td>\n",
       "      <td>37.194646</td>\n",
       "      <td>16.599841</td>\n",
       "      <td>15.381143</td>\n",
       "      <td>44.856534</td>\n",
       "      <td>33.422017</td>\n",
       "      <td>35.672130</td>\n",
       "      <td>25.813912</td>\n",
       "      <td>45.421423</td>\n",
       "      <td>...</td>\n",
       "      <td>0.549328</td>\n",
       "      <td>3.476718</td>\n",
       "      <td>2.004481</td>\n",
       "      <td>0.050173</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.347441</td>\n",
       "      <td>1.425438</td>\n",
       "      <td>13.517617</td>\n",
       "      <td>18.490566</td>\n",
       "      <td>4.407706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>232.000000</td>\n",
       "      <td>108.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-172.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-28.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.800000</td>\n",
       "      <td>-6.000000</td>\n",
       "      <td>-44.200000</td>\n",
       "      <td>-38.600000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>160.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>142.000000</td>\n",
       "      <td>350.000000</td>\n",
       "      <td>148.000000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.450000</td>\n",
       "      <td>6.600000</td>\n",
       "      <td>-2.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>11.400000</td>\n",
       "      <td>17.500000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>164.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>157.000000</td>\n",
       "      <td>367.000000</td>\n",
       "      <td>162.000000</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.800000</td>\n",
       "      <td>-1.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>18.100000</td>\n",
       "      <td>27.900000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>170.000000</td>\n",
       "      <td>78.500000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>174.500000</td>\n",
       "      <td>384.000000</td>\n",
       "      <td>179.000000</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>2.100000</td>\n",
       "      <td>25.850000</td>\n",
       "      <td>41.050000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>780.000000</td>\n",
       "      <td>176.000000</td>\n",
       "      <td>188.000000</td>\n",
       "      <td>524.000000</td>\n",
       "      <td>509.000000</td>\n",
       "      <td>381.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>169.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.400000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>88.800000</td>\n",
       "      <td>115.900000</td>\n",
       "      <td>16.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 275 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0           1           2           3           4           5    \\\n",
       "count  451.000000  451.000000  451.000000  451.000000  451.000000  451.000000   \n",
       "mean    46.407982    0.552106  166.135255   68.144124   88.915743  155.068736   \n",
       "std     16.429846    0.497830   37.194646   16.599841   15.381143   44.856534   \n",
       "min      0.000000    0.000000  105.000000    6.000000   55.000000    0.000000   \n",
       "25%     36.000000    0.000000  160.000000   59.000000   80.000000  142.000000   \n",
       "50%     47.000000    1.000000  164.000000   68.000000   86.000000  157.000000   \n",
       "75%     58.000000    1.000000  170.000000   78.500000   94.000000  174.500000   \n",
       "max     83.000000    1.000000  780.000000  176.000000  188.000000  524.000000   \n",
       "\n",
       "              6           7           8           9    ...         270  \\\n",
       "count  451.000000  451.000000  451.000000  451.000000  ...  451.000000   \n",
       "mean   367.199557  169.940133   89.935698   33.787140  ...   -0.279601   \n",
       "std     33.422017   35.672130   25.813912   45.421423  ...    0.549328   \n",
       "min    232.000000  108.000000    0.000000 -172.000000  ...   -4.100000   \n",
       "25%    350.000000  148.000000   79.000000    4.000000  ...   -0.450000   \n",
       "50%    367.000000  162.000000   91.000000   40.000000  ...    0.000000   \n",
       "75%    384.000000  179.000000  102.000000   66.000000  ...    0.000000   \n",
       "max    509.000000  381.000000  205.000000  169.000000  ...    0.000000   \n",
       "\n",
       "              271         272         273    274         275         276  \\\n",
       "count  451.000000  451.000000  451.000000  451.0  451.000000  451.000000   \n",
       "mean     9.048115   -1.458537    0.003991    0.0    0.513969    1.218625   \n",
       "std      3.476718    2.004481    0.050173    0.0    0.347441    1.425438   \n",
       "min      0.000000  -28.600000    0.000000    0.0   -0.800000   -6.000000   \n",
       "25%      6.600000   -2.100000    0.000000    0.0    0.400000    0.500000   \n",
       "50%      8.800000   -1.100000    0.000000    0.0    0.500000    1.300000   \n",
       "75%     11.200000    0.000000    0.000000    0.0    0.700000    2.100000   \n",
       "max     23.600000    0.000000    0.800000    0.0    2.400000    6.000000   \n",
       "\n",
       "              277         278         279  \n",
       "count  451.000000  451.000000  451.000000  \n",
       "mean    19.317295   29.429047    3.871397  \n",
       "std     13.517617   18.490566    4.407706  \n",
       "min    -44.200000  -38.600000    1.000000  \n",
       "25%     11.400000   17.500000    1.000000  \n",
       "50%     18.100000   27.900000    1.000000  \n",
       "75%     25.850000   41.050000    6.000000  \n",
       "max     88.800000  115.900000   16.000000  \n",
       "\n",
       "[8 rows x 275 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)     #shape displays the number of rows and columns\n",
    "df.describe()       #Describe show us,different statistical functions like mean,max,quartile etc.. of each column \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      False\n",
      "1      False\n",
      "2      False\n",
      "3      False\n",
      "4      False\n",
      "5      False\n",
      "6      False\n",
      "7      False\n",
      "8      False\n",
      "9      False\n",
      "10      True\n",
      "11      True\n",
      "12      True\n",
      "13      True\n",
      "14      True\n",
      "15     False\n",
      "16     False\n",
      "17     False\n",
      "18     False\n",
      "19     False\n",
      "20     False\n",
      "21     False\n",
      "22     False\n",
      "23     False\n",
      "24     False\n",
      "25     False\n",
      "26     False\n",
      "27     False\n",
      "28     False\n",
      "29     False\n",
      "30     False\n",
      "31     False\n",
      "32     False\n",
      "33     False\n",
      "34     False\n",
      "35     False\n",
      "36     False\n",
      "37     False\n",
      "38     False\n",
      "39     False\n",
      "40     False\n",
      "41     False\n",
      "42     False\n",
      "43     False\n",
      "44     False\n",
      "45     False\n",
      "46     False\n",
      "47     False\n",
      "48     False\n",
      "49     False\n",
      "50     False\n",
      "51     False\n",
      "52     False\n",
      "53     False\n",
      "54     False\n",
      "55     False\n",
      "56     False\n",
      "57     False\n",
      "58     False\n",
      "59     False\n",
      "60     False\n",
      "61     False\n",
      "62     False\n",
      "63     False\n",
      "64     False\n",
      "65     False\n",
      "66     False\n",
      "67     False\n",
      "68     False\n",
      "69     False\n",
      "70     False\n",
      "71     False\n",
      "72     False\n",
      "73     False\n",
      "74     False\n",
      "75     False\n",
      "76     False\n",
      "77     False\n",
      "78     False\n",
      "79     False\n",
      "80     False\n",
      "81     False\n",
      "82     False\n",
      "83     False\n",
      "84     False\n",
      "85     False\n",
      "86     False\n",
      "87     False\n",
      "88     False\n",
      "89     False\n",
      "90     False\n",
      "91     False\n",
      "92     False\n",
      "93     False\n",
      "94     False\n",
      "95     False\n",
      "96     False\n",
      "97     False\n",
      "98     False\n",
      "99     False\n",
      "100    False\n",
      "101    False\n",
      "102    False\n",
      "103    False\n",
      "104    False\n",
      "105    False\n",
      "106    False\n",
      "107    False\n",
      "108    False\n",
      "109    False\n",
      "110    False\n",
      "111    False\n",
      "112    False\n",
      "113    False\n",
      "114    False\n",
      "115    False\n",
      "116    False\n",
      "117    False\n",
      "118    False\n",
      "119    False\n",
      "120    False\n",
      "121    False\n",
      "122    False\n",
      "123    False\n",
      "124    False\n",
      "125    False\n",
      "126    False\n",
      "127    False\n",
      "128    False\n",
      "129    False\n",
      "130    False\n",
      "131    False\n",
      "132    False\n",
      "133    False\n",
      "134    False\n",
      "135    False\n",
      "136    False\n",
      "137    False\n",
      "138    False\n",
      "139    False\n",
      "140    False\n",
      "141    False\n",
      "142    False\n",
      "143    False\n",
      "144    False\n",
      "145    False\n",
      "146    False\n",
      "147    False\n",
      "148    False\n",
      "149    False\n",
      "150    False\n",
      "151    False\n",
      "152    False\n",
      "153    False\n",
      "154    False\n",
      "155    False\n",
      "156    False\n",
      "157    False\n",
      "158    False\n",
      "159    False\n",
      "160    False\n",
      "161    False\n",
      "162    False\n",
      "163    False\n",
      "164    False\n",
      "165    False\n",
      "166    False\n",
      "167    False\n",
      "168    False\n",
      "169    False\n",
      "170    False\n",
      "171    False\n",
      "172    False\n",
      "173    False\n",
      "174    False\n",
      "175    False\n",
      "176    False\n",
      "177    False\n",
      "178    False\n",
      "179    False\n",
      "180    False\n",
      "181    False\n",
      "182    False\n",
      "183    False\n",
      "184    False\n",
      "185    False\n",
      "186    False\n",
      "187    False\n",
      "188    False\n",
      "189    False\n",
      "190    False\n",
      "191    False\n",
      "192    False\n",
      "193    False\n",
      "194    False\n",
      "195    False\n",
      "196    False\n",
      "197    False\n",
      "198    False\n",
      "199    False\n",
      "200    False\n",
      "201    False\n",
      "202    False\n",
      "203    False\n",
      "204    False\n",
      "205    False\n",
      "206    False\n",
      "207    False\n",
      "208    False\n",
      "209    False\n",
      "210    False\n",
      "211    False\n",
      "212    False\n",
      "213    False\n",
      "214    False\n",
      "215    False\n",
      "216    False\n",
      "217    False\n",
      "218    False\n",
      "219    False\n",
      "220    False\n",
      "221    False\n",
      "222    False\n",
      "223    False\n",
      "224    False\n",
      "225    False\n",
      "226    False\n",
      "227    False\n",
      "228    False\n",
      "229    False\n",
      "230    False\n",
      "231    False\n",
      "232    False\n",
      "233    False\n",
      "234    False\n",
      "235    False\n",
      "236    False\n",
      "237    False\n",
      "238    False\n",
      "239    False\n",
      "240    False\n",
      "241    False\n",
      "242    False\n",
      "243    False\n",
      "244    False\n",
      "245    False\n",
      "246    False\n",
      "247    False\n",
      "248    False\n",
      "249    False\n",
      "250    False\n",
      "251    False\n",
      "252    False\n",
      "253    False\n",
      "254    False\n",
      "255    False\n",
      "256    False\n",
      "257    False\n",
      "258    False\n",
      "259    False\n",
      "260    False\n",
      "261    False\n",
      "262    False\n",
      "263    False\n",
      "264    False\n",
      "265    False\n",
      "266    False\n",
      "267    False\n",
      "268    False\n",
      "269    False\n",
      "270    False\n",
      "271    False\n",
      "272    False\n",
      "273    False\n",
      "274    False\n",
      "275    False\n",
      "276    False\n",
      "277    False\n",
      "278    False\n",
      "279    False\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):  #showing all rows in jupyter\n",
    "    print((df.dtypes==object))          #There are 5 columns with missing values that are True:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "22\n",
      "1\n",
      "375\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in [10,11,12,13,14]:           #cal the no of missing values in given columns\n",
    "        print((df[i]==\"?\").sum())    #calculating number of question marks from each column one by one\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(13,axis=1,inplace=True)          #dropping cols with missing values - 13th column name was also missing in the raw form above\n",
    "# 1st parameter is index number\n",
    "# 2nd is axis, 0 for rows, 1 for column\n",
    "# 3rd, if true then do operation and return none\n",
    "\n",
    "df[[10,11,12,14]]=df[[10,11,12,14]].replace(\"?\", -1)   #replacing NaN value with ? in missing row of specified columns\n",
    "df[[10,11,12,14]]=df[[10,11,12,14]].astype('float')       #converting to float\n",
    "df.columns=[i for i in range(279)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>269</th>\n",
       "      <th>270</th>\n",
       "      <th>271</th>\n",
       "      <th>272</th>\n",
       "      <th>273</th>\n",
       "      <th>274</th>\n",
       "      <th>275</th>\n",
       "      <th>276</th>\n",
       "      <th>277</th>\n",
       "      <th>278</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "      <td>64</td>\n",
       "      <td>81</td>\n",
       "      <td>174</td>\n",
       "      <td>401</td>\n",
       "      <td>149</td>\n",
       "      <td>39</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.1</td>\n",
       "      <td>20.4</td>\n",
       "      <td>38.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>95</td>\n",
       "      <td>138</td>\n",
       "      <td>163</td>\n",
       "      <td>386</td>\n",
       "      <td>185</td>\n",
       "      <td>102</td>\n",
       "      <td>96</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>-2.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3.4</td>\n",
       "      <td>12.3</td>\n",
       "      <td>49.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>175</td>\n",
       "      <td>94</td>\n",
       "      <td>100</td>\n",
       "      <td>202</td>\n",
       "      <td>380</td>\n",
       "      <td>179</td>\n",
       "      <td>143</td>\n",
       "      <td>28</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.2</td>\n",
       "      <td>-2.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2.6</td>\n",
       "      <td>34.6</td>\n",
       "      <td>61.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>190</td>\n",
       "      <td>80</td>\n",
       "      <td>88</td>\n",
       "      <td>181</td>\n",
       "      <td>360</td>\n",
       "      <td>177</td>\n",
       "      <td>103</td>\n",
       "      <td>-16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.1</td>\n",
       "      <td>-3.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>3.9</td>\n",
       "      <td>25.4</td>\n",
       "      <td>62.8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>169</td>\n",
       "      <td>51</td>\n",
       "      <td>100</td>\n",
       "      <td>167</td>\n",
       "      <td>321</td>\n",
       "      <td>174</td>\n",
       "      <td>91</td>\n",
       "      <td>107</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>12.2</td>\n",
       "      <td>-2.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2.2</td>\n",
       "      <td>13.5</td>\n",
       "      <td>31.1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>446</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>160</td>\n",
       "      <td>70</td>\n",
       "      <td>80</td>\n",
       "      <td>199</td>\n",
       "      <td>382</td>\n",
       "      <td>154</td>\n",
       "      <td>117</td>\n",
       "      <td>-37</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.3</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>-4.4</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>447</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>190</td>\n",
       "      <td>85</td>\n",
       "      <td>100</td>\n",
       "      <td>137</td>\n",
       "      <td>361</td>\n",
       "      <td>201</td>\n",
       "      <td>73</td>\n",
       "      <td>86</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.6</td>\n",
       "      <td>-1.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2.4</td>\n",
       "      <td>38.0</td>\n",
       "      <td>62.4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>448</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>166</td>\n",
       "      <td>68</td>\n",
       "      <td>108</td>\n",
       "      <td>176</td>\n",
       "      <td>365</td>\n",
       "      <td>194</td>\n",
       "      <td>116</td>\n",
       "      <td>-85</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.3</td>\n",
       "      <td>-28.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-44.2</td>\n",
       "      <td>-33.2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>449</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>155</td>\n",
       "      <td>55</td>\n",
       "      <td>93</td>\n",
       "      <td>106</td>\n",
       "      <td>386</td>\n",
       "      <td>218</td>\n",
       "      <td>63</td>\n",
       "      <td>54</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.4</td>\n",
       "      <td>25.0</td>\n",
       "      <td>46.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>78</td>\n",
       "      <td>1</td>\n",
       "      <td>160</td>\n",
       "      <td>70</td>\n",
       "      <td>79</td>\n",
       "      <td>127</td>\n",
       "      <td>364</td>\n",
       "      <td>138</td>\n",
       "      <td>78</td>\n",
       "      <td>28</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.4</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.6</td>\n",
       "      <td>21.3</td>\n",
       "      <td>32.8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>451 rows × 279 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4    5    6    7    8    9    ...  269   270   271  \\\n",
       "0     56    1  165   64   81  174  401  149   39   25  ...  0.0   8.5   0.0   \n",
       "1     54    0  172   95  138  163  386  185  102   96  ...  0.0   9.5  -2.4   \n",
       "2     55    0  175   94  100  202  380  179  143   28  ...  0.0  12.2  -2.2   \n",
       "3     75    0  190   80   88  181  360  177  103  -16  ...  0.0  13.1  -3.6   \n",
       "4     13    0  169   51  100  167  321  174   91  107  ... -0.6  12.2  -2.8   \n",
       "..   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   ...   ...   \n",
       "446   53    1  160   70   80  199  382  154  117  -37  ...  0.0   4.3  -5.0   \n",
       "447   37    0  190   85  100  137  361  201   73   86  ...  0.0  15.6  -1.6   \n",
       "448   36    0  166   68  108  176  365  194  116  -85  ...  0.0  16.3 -28.6   \n",
       "449   32    1  155   55   93  106  386  218   63   54  ... -0.4  12.0  -0.7   \n",
       "450   78    1  160   70   79  127  364  138   78   28  ...  0.0  10.4  -1.8   \n",
       "\n",
       "     272  273  274  275   276   277  278  \n",
       "0    0.0  0.0  0.2  2.1  20.4  38.8    6  \n",
       "1    0.0  0.0  0.3  3.4  12.3  49.0   10  \n",
       "2    0.0  0.0  0.4  2.6  34.6  61.6    1  \n",
       "3    0.0  0.0 -0.1  3.9  25.4  62.8    7  \n",
       "4    0.0  0.0  0.9  2.2  13.5  31.1   14  \n",
       "..   ...  ...  ...  ...   ...   ...  ...  \n",
       "446  0.0  0.0  0.7  0.6  -4.4  -0.5    1  \n",
       "447  0.0  0.0  0.4  2.4  38.0  62.4   10  \n",
       "448  0.0  0.0  1.5  1.0 -44.2 -33.2    2  \n",
       "449  0.0  0.0  0.5  2.4  25.0  46.6    1  \n",
       "450  0.0  0.0  0.5  1.6  21.3  32.8    1  \n",
       "\n",
       "[451 rows x 279 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df   #we print it alone because, if we print it with above statements than in each execution it must drop the index 13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Train/Test Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 24. ,   1. , 163. , ...,   2.1,  44. ,  61.6],\n",
       "       [ 34. ,   0. , 165. , ...,   2.2,  15.1,  30.5],\n",
       "       [ 31. ,   1. , 160. , ...,   3.2,  25.4,  54.8],\n",
       "       ...,\n",
       "       [ 24. ,   1. , 162. , ...,   1.2,   7.4,  15.5],\n",
       "       [ 41. ,   1. , 159. , ...,   1.6,  17.9,  29.4],\n",
       "       [ 56. ,   0. , 168. , ...,   1.1,  23.6,  31.7]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "data=df.values\n",
    "X=data[:,:278]    #independent variables from index 0 to 277\n",
    "Y=data[:,278]     #dependent variable or label Y, 278th index\n",
    "#Y\n",
    "#X\n",
    "X_train,X_test,Y_train,Y_test=model_selection.train_test_split(X,Y,test_size=0.2,random_state=0)    #0.2 means make 20% data for testing e.g.(test_ratio), it means automatically 80% fixed for training\n",
    "X_train\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.345564  ,  0.88940698, -0.08990135, ...,  0.60637399,\n",
       "         1.81945942,  1.7625764 ],\n",
       "       [-0.73854265, -1.12434467, -0.04141523, ...,  0.6775029 ,\n",
       "        -0.31603417,  0.04019806],\n",
       "       [-0.92064905,  0.88940698, -0.16263053, ...,  1.38879203,\n",
       "         0.4450587 ,  1.3859792 ],\n",
       "       ...,\n",
       "       [-1.345564  ,  0.88940698, -0.11414441, ..., -0.03378623,\n",
       "        -0.88500651, -0.79053104],\n",
       "       [-0.3136277 ,  0.88940698, -0.18687359, ...,  0.25072942,\n",
       "        -0.10913513, -0.02072208],\n",
       "       [ 0.59690433, -1.12434467,  0.03131395, ..., -0.10491515,\n",
       "         0.31205218,  0.10665639]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler=StandardScaler()\n",
    "#print(\"Hello\")\n",
    "X_train=scaler.fit_transform(X_train)\n",
    "#\"fit\" computes the mean and std to be used for later scaling.\"transform\" uses a previously computed mean and std to autoscale the data (subtract mean from all values and then divide it by std).\n",
    "X_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.28486186,  0.88940698, -0.11414441, ...,  0.96201855,\n",
       "         0.20860267,  1.07584034],\n",
       "       [ 1.5681385 ,  0.88940698, -0.16263053, ...,  0.96201855,\n",
       "         0.56328672,  0.93738549],\n",
       "       [ 0.23269152,  0.88940698, -0.16263053, ...,  0.6775029 ,\n",
       "        -0.83328175, -0.10379499],\n",
       "       ...,\n",
       "       [-0.01011702, -1.12434467,  0.24950149, ...,  0.25072942,\n",
       "        -0.13130289,  0.01250709],\n",
       "       [-0.13152129,  0.88940698, -0.16263053, ..., -0.74507537,\n",
       "        -1.38747559, -1.52711085],\n",
       "       [ 1.7502449 ,  0.88940698, -0.25960277, ...,  0.03734268,\n",
       "        -0.55987946, -0.48039218]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test=scaler.transform(X_test)\n",
    "X_test\n",
    "\n",
    "#num_feature=len(df.columns)-1\n",
    "#len(set(Y))\n",
    "#num_feature\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Applying KNN (Classification Algorithm 1) \n",
    "#  Default Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = KNeighborsClassifier()   # model object\n",
    "classifier.fit(X_train, Y_train)                #set parameters to object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = classifier.predict(X_test)       #calling predict function, later we use like cost function f(Xi)\n",
    "y_pred_train = classifier.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Result (Default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy Score = 0.6361111111111111\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.61      0.99      0.76       192\n",
      "         2.0       0.62      0.25      0.36        32\n",
      "         3.0       1.00      0.55      0.71        11\n",
      "         4.0       0.89      0.73      0.80        11\n",
      "         5.0       0.00      0.00      0.00        10\n",
      "         6.0       0.20      0.05      0.08        21\n",
      "         7.0       0.00      0.00      0.00         2\n",
      "         8.0       0.00      0.00      0.00         1\n",
      "         9.0       1.00      0.38      0.55         8\n",
      "        10.0       0.92      0.25      0.39        44\n",
      "        14.0       0.00      0.00      0.00         4\n",
      "        15.0       1.00      0.40      0.57         5\n",
      "        16.0       0.00      0.00      0.00        19\n",
      "\n",
      "    accuracy                           0.64       360\n",
      "   macro avg       0.48      0.28      0.32       360\n",
      "weighted avg       0.60      0.64      0.55       360\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "\n",
      " [[190   1   0   0   0   1   0   0   0   0   0   0   0]\n",
      " [ 23   8   0   0   0   0   0   0   0   1   0   0   0]\n",
      " [  5   0   6   0   0   0   0   0   0   0   0   0   0]\n",
      " [  3   0   0   8   0   0   0   0   0   0   0   0   0]\n",
      " [  9   1   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [ 18   1   0   1   0   1   0   0   0   0   0   0   0]\n",
      " [  2   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  1   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  3   0   0   0   0   1   0   0   3   0   0   0   1]\n",
      " [ 32   1   0   0   0   0   0   0   0  11   0   0   0]\n",
      " [  4   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  3   0   0   0   0   0   0   0   0   0   0   2   0]\n",
      " [ 16   1   0   0   0   2   0   0   0   0   0   0   0]]\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "acc_score_train_knn = accuracy_score(Y_train,y_pred_train)          #sending f(Xi) as y_pred_train\n",
    "class_report_train_knn = classification_report(Y_train,y_pred_train)\n",
    "c_matrix_train_knn = confusion_matrix(Y_train,y_pred_train)\n",
    "\n",
    "\n",
    "#res = cross_val_score(classifier, X_train, Y_train, cv=10, scoring='accuracy') #cross validation for 10 samples splits\n",
    "#acc_sd = np.std(res)  #standard daviation of accuracy\n",
    "#acc_avg = np.mean(res) #average of accuracy\n",
    "\n",
    "\n",
    "print(f\"\\nAccuracy Score =\",acc_score_train_knn)\n",
    "print(f\"\\nClassification Report:\\n\\n\",class_report_train_knn)\n",
    "print(f\"\\nConfusion Matrix:\\n\\n\",c_matrix_train_knn)\n",
    "print(\"\\n-----------------------------------------------------------\\n\")\n",
    "#print(f\"\\nAccuracy SD = \",acc_sd)\n",
    "#print(f\"\\nAccuracy Average = \",acc_avg)\n",
    "#print(\"\\n\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Result (Default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy Score = 0.6153846153846154\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.62      0.98      0.76        53\n",
      "         2.0       0.00      0.00      0.00        12\n",
      "         3.0       1.00      0.25      0.40         4\n",
      "         4.0       0.00      0.00      0.00         4\n",
      "         5.0       0.00      0.00      0.00         3\n",
      "         6.0       1.00      0.25      0.40         4\n",
      "         7.0       0.00      0.00      0.00         1\n",
      "         9.0       0.00      0.00      0.00         1\n",
      "        10.0       0.50      0.33      0.40         6\n",
      "        16.0       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.62        91\n",
      "   macro avg       0.31      0.18      0.20        91\n",
      "weighted avg       0.48      0.62      0.50        91\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "\n",
      " [[52  1  0  0  0  0  0  0  0  0]\n",
      " [12  0  0  0  0  0  0  0  0  0]\n",
      " [ 3  0  1  0  0  0  0  0  0  0]\n",
      " [ 4  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  0  2  0]\n",
      " [ 3  0  0  0  0  1  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  0]\n",
      " [ 4  0  0  0  0  0  0  0  2  0]\n",
      " [ 3  0  0  0  0  0  0  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "acc_score_test_knn = accuracy_score(Y_test,y_pred_test)\n",
    "class_report_test_knn = classification_report(Y_test,y_pred_test)\n",
    "c_matrix_test_knn = confusion_matrix(Y_test,y_pred_test)\n",
    "\n",
    "print(f\"\\nAccuracy Score =\",acc_score_test_knn)\n",
    "print(f\"\\nClassification Report:\\n\\n\",class_report_test_knn)\n",
    "print(f\"\\nConfusion Matrix:\\n\\n\",c_matrix_test_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:657: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=4.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6027777777777777\n",
      "{'n_neighbors': 3, 'weights': 'uniform'}\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=3, p=2,\n",
      "                     weights='uniform')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "k_range = list(range(1,40))\n",
    "weight_options = [\"uniform\", \"distance\"]\n",
    "\n",
    "param_grid = dict(n_neighbors = k_range, weights = weight_options)\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "grid = GridSearchCV(knn, param_grid, cv = 4, scoring = 'accuracy')\n",
    "grid.fit(X_train, Y_train)\n",
    "\n",
    "print (grid.best_score_)\n",
    "print (grid.best_params_)\n",
    "print (grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=3, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
    "                     metric_params=None, n_jobs=None, n_neighbors=3, p=2,\n",
    "                     weights='uniform')\n",
    "best_model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_y_pred_test = best_model.predict(X_test)       #calling predict function, later we use like cost function f(Xi)\n",
    "best_y_pred_train = best_model.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Result (Best Parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy Score = 0.7\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.66      0.98      0.79       192\n",
      "         2.0       0.56      0.31      0.40        32\n",
      "         3.0       1.00      0.82      0.90        11\n",
      "         4.0       1.00      0.73      0.84        11\n",
      "         5.0       0.00      0.00      0.00        10\n",
      "         6.0       0.67      0.38      0.48        21\n",
      "         7.0       0.00      0.00      0.00         2\n",
      "         8.0       0.00      0.00      0.00         1\n",
      "         9.0       1.00      0.50      0.67         8\n",
      "        10.0       1.00      0.52      0.69        44\n",
      "        14.0       0.00      0.00      0.00         4\n",
      "        15.0       1.00      0.20      0.33         5\n",
      "        16.0       0.00      0.00      0.00        19\n",
      "\n",
      "    accuracy                           0.70       360\n",
      "   macro avg       0.53      0.34      0.39       360\n",
      "weighted avg       0.66      0.70      0.64       360\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "\n",
      " [[189   1   0   0   0   2   0   0   0   0   0   0   0]\n",
      " [ 21  10   0   0   0   1   0   0   0   0   0   0   0]\n",
      " [  2   0   9   0   0   0   0   0   0   0   0   0   0]\n",
      " [  3   0   0   8   0   0   0   0   0   0   0   0   0]\n",
      " [  8   2   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [ 13   0   0   0   0   8   0   0   0   0   0   0   0]\n",
      " [  2   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  1   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  2   1   0   0   0   1   0   0   4   0   0   0   0]\n",
      " [ 20   1   0   0   0   0   0   0   0  23   0   0   0]\n",
      " [  4   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  4   0   0   0   0   0   0   0   0   0   0   1   0]\n",
      " [ 16   3   0   0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "best_acc_score_train_knn = accuracy_score(Y_train,best_y_pred_train)          #sending f(Xi) as y_pred_train\n",
    "best_class_report_train_knn = classification_report(Y_train,best_y_pred_train)\n",
    "best_c_matrix_train_knn = confusion_matrix(Y_train,best_y_pred_train)\n",
    "\n",
    "print(f\"\\nAccuracy Score =\",best_acc_score_train_knn)\n",
    "print(f\"\\nClassification Report:\\n\\n\",best_class_report_train_knn)\n",
    "print(f\"\\nConfusion Matrix:\\n\\n\",best_c_matrix_train_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Result (Best Parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy Score = 0.6813186813186813\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.67      0.98      0.79        53\n",
      "         2.0       0.67      0.17      0.27        12\n",
      "         3.0       1.00      0.75      0.86         4\n",
      "         4.0       1.00      0.25      0.40         4\n",
      "         5.0       1.00      0.33      0.50         3\n",
      "         6.0       0.00      0.00      0.00         4\n",
      "         7.0       0.00      0.00      0.00         1\n",
      "         9.0       0.00      0.00      0.00         1\n",
      "        10.0       0.75      0.50      0.60         6\n",
      "        16.0       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.68        91\n",
      "   macro avg       0.51      0.30      0.34        91\n",
      "weighted avg       0.65      0.68      0.61        91\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "\n",
      " [[52  0  0  0  0  1  0  0  0  0]\n",
      " [10  2  0  0  0  0  0  0  0  0]\n",
      " [ 1  0  3  0  0  0  0  0  0  0]\n",
      " [ 3  0  0  1  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  1  0  0  0  1  0]\n",
      " [ 4  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  1  0  0  0  0  0  0  0  0]\n",
      " [ 3  0  0  0  0  0  0  0  3  0]\n",
      " [ 3  0  0  0  0  0  0  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "best_acc_score_test_knn = accuracy_score(Y_test,best_y_pred_test)\n",
    "best_class_report_test_knn = classification_report(Y_test,best_y_pred_test)\n",
    "best_c_matrix_test_knn = confusion_matrix(Y_test,best_y_pred_test)\n",
    "\n",
    "print(f\"\\nAccuracy Score =\",best_acc_score_test_knn)\n",
    "print(f\"\\nClassification Report:\\n\\n\",best_class_report_test_knn)\n",
    "print(f\"\\nConfusion Matrix:\\n\\n\",best_c_matrix_test_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Applying Logistic Regression (Classification Algorithm 2) \n",
    "\n",
    "#  Default Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log=LogisticRegression()\n",
    "log.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test_log = log.predict(X_test)       #calling predict function, later we use like cost function f(Xi)\n",
    "y_pred_train_log = log.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Result (Default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy Score = 0.9777777777777777\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.96      0.99      0.98       192\n",
      "         2.0       1.00      1.00      1.00        32\n",
      "         3.0       1.00      1.00      1.00        11\n",
      "         4.0       1.00      1.00      1.00        11\n",
      "         5.0       1.00      1.00      1.00        10\n",
      "         6.0       1.00      0.90      0.95        21\n",
      "         7.0       1.00      0.50      0.67         2\n",
      "         8.0       1.00      1.00      1.00         1\n",
      "         9.0       1.00      1.00      1.00         8\n",
      "        10.0       0.98      0.98      0.98        44\n",
      "        14.0       1.00      1.00      1.00         4\n",
      "        15.0       1.00      1.00      1.00         5\n",
      "        16.0       1.00      0.84      0.91        19\n",
      "\n",
      "    accuracy                           0.98       360\n",
      "   macro avg       1.00      0.94      0.96       360\n",
      "weighted avg       0.98      0.98      0.98       360\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "\n",
      " [[191   0   0   0   0   0   0   0   0   1   0   0   0]\n",
      " [  0  32   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0  11   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0  11   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0  10   0   0   0   0   0   0   0   0]\n",
      " [  2   0   0   0   0  19   0   0   0   0   0   0   0]\n",
      " [  1   0   0   0   0   0   1   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   1   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   8   0   0   0   0]\n",
      " [  1   0   0   0   0   0   0   0   0  43   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   4   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   5   0]\n",
      " [  3   0   0   0   0   0   0   0   0   0   0   0  16]]\n"
     ]
    }
   ],
   "source": [
    "acc_score_train_log = accuracy_score(Y_train,y_pred_train_log)          #sending f(Xi) as y_pred_train\n",
    "class_report_train_log = classification_report(Y_train,y_pred_train_log)\n",
    "c_matrix_train_log = confusion_matrix(Y_train,y_pred_train_log)\n",
    "\n",
    "\n",
    "\n",
    "print(f\"\\nAccuracy Score =\",acc_score_train_log)\n",
    "print(f\"\\nClassification Report:\\n\\n\",class_report_train_log)\n",
    "print(f\"\\nConfusion Matrix:\\n\\n\",c_matrix_train_log)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Result (Default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy Score = 0.6593406593406593\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.81      0.81      0.81        53\n",
      "         2.0       0.67      0.33      0.44        12\n",
      "         3.0       0.67      1.00      0.80         4\n",
      "         4.0       1.00      0.75      0.86         4\n",
      "         5.0       0.00      0.00      0.00         3\n",
      "         6.0       0.14      0.25      0.18         4\n",
      "         7.0       0.00      0.00      0.00         1\n",
      "         9.0       1.00      1.00      1.00         1\n",
      "        10.0       0.57      0.67      0.62         6\n",
      "        16.0       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.66        91\n",
      "   macro avg       0.49      0.48      0.47        91\n",
      "weighted avg       0.69      0.66      0.66        91\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "\n",
      " [[43  2  0  0  0  4  0  0  3  1]\n",
      " [ 3  4  1  0  1  1  0  0  0  2]\n",
      " [ 0  0  4  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  3  1  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  2]\n",
      " [ 3  0  0  0  0  1  0  0  0  0]\n",
      " [ 0  0  1  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  1  0  0]\n",
      " [ 2  0  0  0  0  0  0  0  4  0]\n",
      " [ 1  0  0  0  1  1  0  0  0  0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "acc_score_test_log = accuracy_score(Y_test,y_pred_test_log)          #sending f(Xi) as y_pred_train\n",
    "class_report_test_log = classification_report(Y_test,y_pred_test_log)\n",
    "c_matrix_test_log = confusion_matrix(Y_test,y_pred_test_log)\n",
    "\n",
    "\n",
    "\n",
    "print(f\"\\nAccuracy Score =\",acc_score_test_log)\n",
    "print(f\"\\nClassification Report:\\n\\n\",class_report_test_log)\n",
    "print(f\"\\nConfusion Matrix:\\n\\n\",c_matrix_test_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6: Applying SVM (Classification Algorithm 3) \n",
    "\n",
    "# Default Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc=svm.SVC()\n",
    "svc.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test_svm = svc.predict(X_test)       #calling predict function, later we use like cost function f(Xi)\n",
    "y_pred_train_svm = svc.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Result (Default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy Score = 0.7777777777777778\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.71      1.00      0.83       192\n",
      "         2.0       0.89      0.53      0.67        32\n",
      "         3.0       1.00      0.91      0.95        11\n",
      "         4.0       1.00      0.82      0.90        11\n",
      "         5.0       1.00      0.30      0.46        10\n",
      "         6.0       1.00      0.05      0.09        21\n",
      "         7.0       0.00      0.00      0.00         2\n",
      "         8.0       0.00      0.00      0.00         1\n",
      "         9.0       1.00      1.00      1.00         8\n",
      "        10.0       0.97      0.75      0.85        44\n",
      "        14.0       1.00      0.50      0.67         4\n",
      "        15.0       1.00      0.40      0.57         5\n",
      "        16.0       1.00      0.16      0.27        19\n",
      "\n",
      "    accuracy                           0.78       360\n",
      "   macro avg       0.81      0.49      0.56       360\n",
      "weighted avg       0.83      0.78      0.73       360\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "\n",
      " [[192   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [ 15  17   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  1   0  10   0   0   0   0   0   0   0   0   0   0]\n",
      " [  2   0   0   9   0   0   0   0   0   0   0   0   0]\n",
      " [  7   0   0   0   3   0   0   0   0   0   0   0   0]\n",
      " [ 20   0   0   0   0   1   0   0   0   0   0   0   0]\n",
      " [  2   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  1   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   8   0   0   0   0]\n",
      " [ 11   0   0   0   0   0   0   0   0  33   0   0   0]\n",
      " [  1   1   0   0   0   0   0   0   0   0   2   0   0]\n",
      " [  2   1   0   0   0   0   0   0   0   0   0   2   0]\n",
      " [ 15   0   0   0   0   0   0   0   0   1   0   0   3]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "acc_score_train_svm = accuracy_score(Y_train,y_pred_train_svm)             #sending f(Xi) as y_pred_train\n",
    "class_report_train_svm = classification_report(Y_train,y_pred_train_svm)\n",
    "c_matrix_train_svm = confusion_matrix(Y_train,y_pred_train_svm)\n",
    "\n",
    "\n",
    "print(f\"\\nAccuracy Score =\",acc_score_train_svm)\n",
    "print(f\"\\nClassification Report:\\n\\n\",class_report_train_svm)\n",
    "print(f\"\\nConfusion Matrix:\\n\\n\",c_matrix_train_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Result (Delfault)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy Score = 0.6703296703296703\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.65      1.00      0.79        53\n",
      "         2.0       1.00      0.25      0.40        12\n",
      "         3.0       1.00      0.25      0.40         4\n",
      "         4.0       0.00      0.00      0.00         4\n",
      "         5.0       0.00      0.00      0.00         3\n",
      "         6.0       0.00      0.00      0.00         4\n",
      "         7.0       0.00      0.00      0.00         1\n",
      "         9.0       0.00      0.00      0.00         1\n",
      "        10.0       0.67      0.67      0.67         6\n",
      "        16.0       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.67        91\n",
      "   macro avg       0.33      0.22      0.23        91\n",
      "weighted avg       0.60      0.67      0.58        91\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "\n",
      " [[53  0  0  0  0  0  0  0  0  0]\n",
      " [ 8  3  0  0  0  0  0  0  1  0]\n",
      " [ 3  0  1  0  0  0  0  0  0  0]\n",
      " [ 4  0  0  0  0  0  0  0  0  0]\n",
      " [ 2  0  0  0  0  0  0  0  1  0]\n",
      " [ 4  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  0]\n",
      " [ 2  0  0  0  0  0  0  0  4  0]\n",
      " [ 3  0  0  0  0  0  0  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "acc_score_test_svm = accuracy_score(Y_test,y_pred_test_svm)          #sending f(Xi) as y_pred_train\n",
    "class_report_test_svm = classification_report(Y_test,y_pred_test_svm)\n",
    "c_matrix_test_svm = confusion_matrix(Y_test,y_pred_test_svm)\n",
    "\n",
    "\n",
    "\n",
    "print(f\"\\nAccuracy Score =\",acc_score_test_svm)\n",
    "print(f\"\\nClassification Report:\\n\\n\",class_report_test_svm)\n",
    "print(f\"\\nConfusion Matrix:\\n\\n\",c_matrix_test_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:657: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=3.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=100.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma=0.0001, kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = svm.SVC()\n",
    "grid={'C':[1e2,1e3,5e3,1e4,5e4,1e5],'gamma':[1e-3,1e-4,5e-4,5e-3]}\n",
    "abc=GridSearchCV(svc,grid)\n",
    "abc.fit(X_train,Y_train)\n",
    "abc.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=100.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma=0.0001, kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_model=SVC(C=100.0, cache_size=200, class_weight=None, coef0=0.0,\n",
    "    decision_function_shape='ovr', degree=3, gamma=0.0001, kernel='rbf',\n",
    "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
    "    tol=0.001, verbose=False)\n",
    "svm_model.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_y_pred_test_svm = svm_model.predict(X_test)       #calling predict function, later we use like cost function f(Xi)\n",
    "best_y_pred_train_svm = svm_model.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Result (Best Parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy Score = 0.8972222222222223\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.84      0.99      0.91       192\n",
      "         2.0       1.00      0.75      0.86        32\n",
      "         3.0       1.00      1.00      1.00        11\n",
      "         4.0       1.00      1.00      1.00        11\n",
      "         5.0       1.00      0.60      0.75        10\n",
      "         6.0       1.00      0.52      0.69        21\n",
      "         7.0       1.00      0.50      0.67         2\n",
      "         8.0       1.00      1.00      1.00         1\n",
      "         9.0       1.00      1.00      1.00         8\n",
      "        10.0       0.98      0.91      0.94        44\n",
      "        14.0       1.00      1.00      1.00         4\n",
      "        15.0       1.00      1.00      1.00         5\n",
      "        16.0       1.00      0.53      0.69        19\n",
      "\n",
      "    accuracy                           0.90       360\n",
      "   macro avg       0.99      0.83      0.88       360\n",
      "weighted avg       0.91      0.90      0.89       360\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "\n",
      " [[191   0   0   0   0   0   0   0   0   1   0   0   0]\n",
      " [  8  24   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0  11   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0  11   0   0   0   0   0   0   0   0   0]\n",
      " [  4   0   0   0   6   0   0   0   0   0   0   0   0]\n",
      " [ 10   0   0   0   0  11   0   0   0   0   0   0   0]\n",
      " [  1   0   0   0   0   0   1   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   1   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   8   0   0   0   0]\n",
      " [  4   0   0   0   0   0   0   0   0  40   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   4   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   5   0]\n",
      " [  9   0   0   0   0   0   0   0   0   0   0   0  10]]\n"
     ]
    }
   ],
   "source": [
    "best_acc_score_train_svm = accuracy_score(Y_train,best_y_pred_train_svm)             #sending f(Xi) as y_pred_train\n",
    "best_class_report_train_svm = classification_report(Y_train,best_y_pred_train_svm)\n",
    "best_c_matrix_train_svm = confusion_matrix(Y_train,best_y_pred_train_svm)\n",
    "\n",
    "\n",
    "print(f\"\\nAccuracy Score =\",best_acc_score_train_svm)\n",
    "print(f\"\\nClassification Report:\\n\\n\",best_class_report_train_svm)\n",
    "print(f\"\\nConfusion Matrix:\\n\\n\",best_c_matrix_train_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Result (Best Parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy Score = 0.7802197802197802\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.82      0.96      0.89        53\n",
      "         2.0       1.00      0.50      0.67        12\n",
      "         3.0       0.80      1.00      0.89         4\n",
      "         4.0       1.00      0.50      0.67         4\n",
      "         5.0       1.00      0.33      0.50         3\n",
      "         6.0       0.50      0.50      0.50         4\n",
      "         7.0       0.00      0.00      0.00         1\n",
      "         9.0       0.50      1.00      0.67         1\n",
      "        10.0       0.67      0.67      0.67         6\n",
      "        14.0       0.00      0.00      0.00         0\n",
      "        16.0       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.78        91\n",
      "   macro avg       0.57      0.50      0.49        91\n",
      "weighted avg       0.79      0.78      0.76        91\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "\n",
      " [[51  0  0  0  0  0  0  0  1  0  1]\n",
      " [ 3  6  0  0  0  1  0  0  0  1  1]\n",
      " [ 0  0  4  0  0  0  0  0  0  0  0]\n",
      " [ 2  0  0  2  0  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  1  0  0  0  1  0  0]\n",
      " [ 2  0  0  0  0  2  0  0  0  0  0]\n",
      " [ 0  0  1  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  1  0  0  0]\n",
      " [ 2  0  0  0  0  0  0  0  4  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  1  0  1  0  0  0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "best_acc_score_test_svm = accuracy_score(Y_test,best_y_pred_test_svm)          #sending f(Xi) as y_pred_train\n",
    "best_class_report_test_svm = classification_report(Y_test,best_y_pred_test_svm)\n",
    "best_c_matrix_test_svm = confusion_matrix(Y_test,best_y_pred_test_svm)\n",
    "\n",
    "\n",
    "print(f\"\\nAccuracy Score =\",best_acc_score_test_svm)\n",
    "print(f\"\\nClassification Report:\\n\\n\",best_class_report_test_svm)\n",
    "print(f\"\\nConfusion Matrix:\\n\\n\",best_c_matrix_test_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
